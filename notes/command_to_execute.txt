ETL of ALL DATA:
time spark-submit --conf spark.dynamicAllocation.enabled=false --num-executors=96 --executor-cores=16 --executor-memory=100G new_etl.py amazon_raw_datasets etl_final_1995_2015 1995 2015 >> final_logs_with_broadcast.txt

Basic Queries over smaller subsets of data:
time spark-submit reviews_day_of_week.py etl_final_2000_2005

Query for converting parquet to CSV category wise:
time spark-submit parquet_to_csv_single_category.py "etl_final_1995_2015/product_category=Gift Card" csv_GF_1995_2015 "Gift Card"

Special Days Count:
spark-submit special_days_count.py "etl_final_1995_2015/product_category=Electronics" 1995 2015 "Electronics"


